{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    "> Classes and helper fuction for creating flexible 2D and 3D unets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _get_conv(ndim: int):\n",
    "    \"Get Convolution Layer of any dimension\"\n",
    "    assert 1 <= ndim <=3\n",
    "    return getattr(nn, f'Conv{ndim}d')\n",
    "\n",
    "def _get_bn(ndim: int):\n",
    "    \"Get BatchNorm Layer of any dimension\"\n",
    "    assert 1 <= ndim <=3\n",
    "    return getattr(nn, f'BatchNorm{ndim}d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(_get_conv(1), torch.nn.modules.conv.Conv1d)\n",
    "test_eq(_get_conv(2), torch.nn.modules.conv.Conv2d)\n",
    "test_eq(_get_conv(3), torch.nn.modules.conv.Conv3d)\n",
    "test_eq(_get_bn(1), torch.nn.modules.batchnorm.BatchNorm1d)\n",
    "test_eq(_get_bn(2), torch.nn.modules.batchnorm.BatchNorm2d)\n",
    "test_eq(_get_bn(3), torch.nn.modules.batchnorm.BatchNorm3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"_get_conv\" class=\"doc_header\"><code>_get_conv</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>_get_conv</code>(**`ndim`**:`int`)\n",
       "\n",
       "Get Convolution Layer of any dimension"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(_get_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"_get_bn\" class=\"doc_header\"><code>_get_bn</code><a href=\"__main__.py#L7\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>_get_bn</code>(**`ndim`**:`int`)\n",
       "\n",
       "Get BatchNorm Layer of any dimension"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(_get_bn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "def layer_types(m):\n",
    "    \"returns list of pytorch models type\"\n",
    "    if isinstance(m, list): return list(map(type, m))\n",
    "    return list(map(type, m.children()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def extract_layer(m, name=torch.nn.modules.Conv3d):\n",
    "    res = []\n",
    "    for child in m.children():\n",
    "        for layer in child.modules():\n",
    "            if(isinstance(layer,name)):\n",
    "                res.append(layer)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class FlexConvLayer(nn.Sequential):\n",
    "    '''Create Flexible Conv Layers\n",
    "       \\n`ni`: in_channels\n",
    "       \\n`nf`: out_channels\n",
    "       \\n`ks`: kernal_size\n",
    "       \\n`st`: stride\n",
    "       \\n`pd`: padding default is 1 \n",
    "       \\n`sf`: scale factore if for upsampling layer\n",
    "       \\n`bn`: adds BatchNorm layer if `True`\n",
    "       \\n`ups`: adds Upsampling layer if `True`\n",
    "       \\n`ndim`: number of dimensions for layers e.g if 3 will create `nn.Conv3D` or `nn.BatchNorm3d`\n",
    "       \\n`xtra`: adds any extra nn.Layers\n",
    "       \\n`act_fn`: activation function'''\n",
    "    def __init__(self, ni, nf,ks=3, st=1, ndim=3, sf=2, pd=None, act_fn=None, bn=False, xtra=None, ups=False, **kwargs):\n",
    "        layers = []\n",
    "        if pd is None: pd = 1\n",
    "        layers.append(_get_conv(ndim)(in_channels=ni, out_channels=nf,kernel_size =ks, stride=st, padding=pd, **kwargs))\n",
    "        if ups       : layers.insert(0, nn.Upsample(scale_factor=sf))\n",
    "        if bn        : layers.append(_get_bn(ndim)(nf))\n",
    "        if act_fn    : layers.append(act_fn)\n",
    "        if xtra      : layers.append(xtra)\n",
    "        super().__init__(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h2 id=\"FlexConvLayer\" class=\"doc_header\"><code>class</code> <code>FlexConvLayer</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h2>\n",
       "\n",
       "> <code>FlexConvLayer</code>(**`ni`**, **`nf`**, **`ks`**=*`3`*, **`st`**=*`1`*, **`ndim`**=*`3`*, **`sf`**=*`2`*, **`pd`**=*`None`*, **`act_fn`**=*`None`*, **`bn`**=*`False`*, **`xtra`**=*`None`*, **`ups`**=*`False`*, **\\*\\*`kwargs`**) :: `Sequential`\n",
       "\n",
       "Create Flexible Conv Layers\n",
       "       \n",
       "`ni`: in_channels\n",
       "       \n",
       "`nf`: out_channels\n",
       "       \n",
       "`ks`: kernal_size\n",
       "       \n",
       "`st`: stride\n",
       "       \n",
       "`pd`: padding default is 1 \n",
       "       \n",
       "`sf`: scale factore if for upsampling layer\n",
       "       \n",
       "`bn`: adds BatchNorm layer if `True`\n",
       "       \n",
       "`ups`: adds Upsampling layer if `True`\n",
       "       \n",
       "`ndim`: number of dimensions for layers e.g if 3 will create `nn.Conv3D` or `nn.BatchNorm3d`\n",
       "       \n",
       "`xtra`: adds any extra nn.Layers\n",
       "       \n",
       "`act_fn`: activation function"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(FlexConvLayer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(layer_types(FlexConvLayer(1, 2)), [torch.nn.modules.conv.Conv3d])\n",
    "test_eq(layer_types(FlexConvLayer(1, 2, bn=True)), [torch.nn.modules.conv.Conv3d, torch.nn.modules.batchnorm.BatchNorm3d])\n",
    "test_eq(layer_types(FlexConvLayer(1, 2, bn=True)), [torch.nn.modules.conv.Conv3d, torch.nn.modules.batchnorm.BatchNorm3d])\n",
    "test_eq(layer_types(FlexConvLayer(1, 2, bn=True, ups=True)), [torch.nn.modules.upsampling.Upsample, torch.nn.modules.conv.Conv3d, torch.nn.modules.batchnorm.BatchNorm3d])\n",
    "test_eq(layer_types(FlexConvLayer(1, 2, bn=True, ups=True, act_fn=nn.ELU())), [torch.nn.modules.upsampling.Upsample, torch.nn.modules.conv.Conv3d, torch.nn.modules.batchnorm.BatchNorm3d,  torch.nn.modules.activation.ELU])\n",
    "test_eq(layer_types(FlexConvLayer(1, 2, bn=True, ups=True, act_fn=nn.ELU(), xtra=nn.ReLU())), [torch.nn.modules.upsampling.Upsample, torch.nn.modules.conv.Conv3d, torch.nn.modules.batchnorm.BatchNorm3d,  torch.nn.modules.activation.ELU, torch.nn.modules.activation.ReLU])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "class FlexUnetEncoder(nn.Module):\n",
    "    '''Creates flexible encoder for Unets\n",
    "       \\n`ni`: in_channels\n",
    "       \\n`nf`: out_channels\n",
    "       \\n`ks`: kernal_size\n",
    "       \\n`st`: stride\n",
    "       \\n`pd`: padding default is 1 \n",
    "       \\n`bn`: adds BatchNorm layer if `True`\n",
    "       \\n`act_fn`: activation function\n",
    "       \\n`conv_depth`: number of conv layers\n",
    "       '''\n",
    "    \n",
    "    def __init__(self, ni, nf, ks, st, pd, conv_depth, ndim=3,  act_fn=nn.ELU()):\n",
    "        super().__init__()\n",
    "        nf = nf\n",
    "        self.module_dict = nn.ModuleDict()\n",
    "        self.module_dict[f'pass_n'] = FlexConvLayer(ni, nf, act_fn=act_fn, ndim=ndim)\n",
    "        self.module_dict[f'save_n'] = FlexConvLayer(nf, nf, act_fn=act_fn, ndim=ndim)\n",
    "        for i in range(conv_depth):\n",
    "            self.module_dict[f'pass_{i}_k'] = nn.Sequential(FlexConvLayer(nf, nf, ks=ks-1, st=st + 1, act_fn=act_fn, pd=pd, ndim=ndim))\n",
    "            self.module_dict[f'save_{i}'] = nn.Sequential(FlexConvLayer(nf, nf*2, ks=ks, st=st, act_fn=act_fn, ndim=ndim), )\n",
    "            self.module_dict[f'pass_{i}'] = nn.Sequential(FlexConvLayer(nf*2, nf*2, ks=ks, st=st, act_fn=act_fn, ndim=ndim))\n",
    "            nf *=2\n",
    "    def forward(self, x):\n",
    "        features = []\n",
    "        for i in self.module_dict:\n",
    "            if     i.startswith('pass'): x = self.module_dict[i](x)\n",
    "            else:  x = self.module_dict[i](x) ;features.append(x)\n",
    "        return (x, features[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h2 id=\"FlexUnetEncoder\" class=\"doc_header\"><code>class</code> <code>FlexUnetEncoder</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h2>\n",
       "\n",
       "> <code>FlexUnetEncoder</code>(**`ni`**, **`nf`**, **`ks`**, **`st`**, **`pd`**, **`conv_depth`**, **`ndim`**=*`3`*, **`act_fn`**=*`ELU(alpha=1.0)`*) :: `Module`\n",
       "\n",
       "Creates flexible encoder for Unets\n",
       "       \n",
       "`ni`: in_channels\n",
       "       \n",
       "`nf`: out_channels\n",
       "       \n",
       "`ks`: kernal_size\n",
       "       \n",
       "`st`: stride\n",
       "       \n",
       "`pd`: padding default is 1 \n",
       "       \n",
       "`bn`: adds BatchNorm layer if `True`\n",
       "       \n",
       "`act_fn`: activation function\n",
       "       \n",
       "`conv_depth`: number of conv layers\n",
       "       "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(FlexUnetEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FlexUnetEncoder(\n",
       "  (module_dict): ModuleDict(\n",
       "    (pass_n): FlexConvLayer(\n",
       "      (0): Conv3d(1, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (1): ELU(alpha=1.0)\n",
       "    )\n",
       "    (save_n): FlexConvLayer(\n",
       "      (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (1): ELU(alpha=1.0)\n",
       "    )\n",
       "    (pass_0_k): Sequential(\n",
       "      (0): FlexConvLayer(\n",
       "        (0): Conv3d(48, 48, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
       "        (1): ELU(alpha=1.0)\n",
       "      )\n",
       "    )\n",
       "    (save_0): Sequential(\n",
       "      (0): FlexConvLayer(\n",
       "        (0): Conv3d(48, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "        (1): ELU(alpha=1.0)\n",
       "      )\n",
       "    )\n",
       "    (pass_0): Sequential(\n",
       "      (0): FlexConvLayer(\n",
       "        (0): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "        (1): ELU(alpha=1.0)\n",
       "      )\n",
       "    )\n",
       "    (pass_1_k): Sequential(\n",
       "      (0): FlexConvLayer(\n",
       "        (0): Conv3d(96, 96, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
       "        (1): ELU(alpha=1.0)\n",
       "      )\n",
       "    )\n",
       "    (save_1): Sequential(\n",
       "      (0): FlexConvLayer(\n",
       "        (0): Conv3d(96, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "        (1): ELU(alpha=1.0)\n",
       "      )\n",
       "    )\n",
       "    (pass_1): Sequential(\n",
       "      (0): FlexConvLayer(\n",
       "        (0): Conv3d(192, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "        (1): ELU(alpha=1.0)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst_encoder = FlexUnetEncoder(1, 48, 3, 1, 0, conv_depth=2, ndim=3)\n",
    "tst_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(len(extract_layer(tst_encder)), 8)\n",
    "test_eq(layer_types(extract_layer(tst_encder))[:1], [torch.nn.modules.conv.Conv3d])\n",
    "test_eq(layer_types(extract_layer(tst_encder)), [torch.nn.modules.conv.Conv3d]*8)\n",
    "test_eq(getattr(extract_layer(tst_encder)[0], 'kernel_size'), (3, 3, 3))\n",
    "test_eq(getattr(extract_layer(tst_encder)[0], 'stride'), (1, 1, 1))\n",
    "test_eq(getattr(extract_layer(tst_encder)[0], 'padding'), (1, 1, 1))\n",
    "test_eq(getattr(extract_layer(tst_encder)[2], 'padding'), (0, 0, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
