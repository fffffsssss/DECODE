{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    "> Classes and helper fuction for creating flexible 2D and 3D unets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *\n",
    "from pdb import set_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _get_conv(ndim: int):\n",
    "    \"Get Convolution Layer of any dimension\"\n",
    "    assert 1 <= ndim <=3\n",
    "    return getattr(nn, f'Conv{ndim}d')\n",
    "\n",
    "def _get_bn(ndim: int):\n",
    "    \"Get BatchNorm Layer of any dimension\"\n",
    "    assert 1 <= ndim <=3\n",
    "    return getattr(nn, f'BatchNorm{ndim}d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(_get_conv(1), torch.nn.modules.conv.Conv1d)\n",
    "test_eq(_get_conv(2), torch.nn.modules.conv.Conv2d)\n",
    "test_eq(_get_conv(3), torch.nn.modules.conv.Conv3d)\n",
    "test_eq(_get_bn(1), torch.nn.modules.batchnorm.BatchNorm1d)\n",
    "test_eq(_get_bn(2), torch.nn.modules.batchnorm.BatchNorm2d)\n",
    "test_eq(_get_bn(3), torch.nn.modules.batchnorm.BatchNorm3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"_get_conv\" class=\"doc_header\"><code>_get_conv</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>_get_conv</code>(**`ndim`**:`int`)\n",
       "\n",
       "Get Convolution Layer of any dimension"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(_get_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"_get_bn\" class=\"doc_header\"><code>_get_bn</code><a href=\"__main__.py#L7\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>_get_bn</code>(**`ndim`**:`int`)\n",
       "\n",
       "Get BatchNorm Layer of any dimension"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(_get_bn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def init_func(m, func=nn.init.kaiming_normal_):\n",
    "    \"Initialize pytorch model `m` weights with `func`\"\n",
    "    if func and hasattr(m, 'weight'): func(m.weight)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"init_func\" class=\"doc_header\"><code>init_func</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>init_func</code>(**`m`**, **`func`**=*`'kaiming_normal_'`*)\n",
       "\n",
       "Initialize pytorch model `m` weights with `func`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(init_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "def layer_types(m):\n",
    "    \"returns list of pytorch models type\"\n",
    "    if isinstance(m, list): return list(map(type, m))\n",
    "    return list(map(type, m.children()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def extract_layer(m, name=torch.nn.modules.Conv3d):\n",
    "    res = []\n",
    "    for child in m.children():\n",
    "        for layer in child.modules():\n",
    "            if(isinstance(layer,name)):\n",
    "                res.append(layer)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class FlexConvLayer(nn.Sequential):\n",
    "    '''Create Flexible Conv Layers\n",
    "       \\n`ni`: in_channels\n",
    "       \\n`nf`: out_channels\n",
    "       \\n`ks`: kernal_size\n",
    "       \\n`st`: stride\n",
    "       \\n`pd`: padding default is 1 \n",
    "       \\n`sf`: scale factore if for upsampling layer\n",
    "       \\n`bn`: adds BatchNorm layer if `True`\n",
    "       \\n`ups`: adds Upsampling layer if `True`\n",
    "       \\n`ndim`: number of dimensions for layers e.g if 3 will create `nn.Conv3D` or `nn.BatchNorm3d`\n",
    "       \\n`func`: initiation function by default `nn.init.kaiming_normal_`\n",
    "       \\n`xtra`: adds any extra nn.Layers\n",
    "       \\n`act_fn`: activation function'''\n",
    "    def __init__(self, ni, nf,ks=3, st=1, ndim=3, sf=2, pd=None, act_fn=None, bn=False, xtra=None, ups=False, func=nn.init.kaiming_normal_, **kwargs):\n",
    "        \n",
    "        layers = []\n",
    "        if pd is None: pd = 1\n",
    "        conv_l = _get_conv(ndim)(in_channels=ni, out_channels=nf,kernel_size =ks, stride=st, padding=pd, **kwargs)\n",
    "        init_func(conv_l, func)\n",
    "        layers.append(conv_l)\n",
    "        if ups       : layers.insert(0, nn.Upsample(scale_factor=sf))\n",
    "        if bn        : layers.append(_get_bn(ndim)(nf))\n",
    "        if act_fn    : layers.append(act_fn())\n",
    "        if xtra      : layers.append(xtra)\n",
    "        super().__init__(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h2 id=\"FlexConvLayer\" class=\"doc_header\"><code>class</code> <code>FlexConvLayer</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h2>\n",
       "\n",
       "> <code>FlexConvLayer</code>(**`ni`**, **`nf`**, **`ks`**=*`3`*, **`st`**=*`1`*, **`ndim`**=*`3`*, **`sf`**=*`2`*, **`pd`**=*`None`*, **`act_fn`**=*`None`*, **`bn`**=*`False`*, **`xtra`**=*`None`*, **`ups`**=*`False`*, **`func`**=*`'kaiming_normal_'`*, **\\*\\*`kwargs`**) :: `Sequential`\n",
       "\n",
       "Create Flexible Conv Layers\n",
       "       \n",
       "`ni`: in_channels\n",
       "       \n",
       "`nf`: out_channels\n",
       "       \n",
       "`ks`: kernal_size\n",
       "       \n",
       "`st`: stride\n",
       "       \n",
       "`pd`: padding default is 1 \n",
       "       \n",
       "`sf`: scale factore if for upsampling layer\n",
       "       \n",
       "`bn`: adds BatchNorm layer if `True`\n",
       "       \n",
       "`ups`: adds Upsampling layer if `True`\n",
       "       \n",
       "`ndim`: number of dimensions for layers e.g if 3 will create `nn.Conv3D` or `nn.BatchNorm3d`\n",
       "       \n",
       "`func`: initiation function by default `nn.init.kaiming_normal_`\n",
       "       \n",
       "`xtra`: adds any extra nn.Layers\n",
       "       \n",
       "`act_fn`: activation function"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(FlexConvLayer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(layer_types(FlexConvLayer(1, 2)), [torch.nn.modules.conv.Conv3d])\n",
    "test_eq(layer_types(FlexConvLayer(1, 2, bn=True)), [torch.nn.modules.conv.Conv3d, torch.nn.modules.batchnorm.BatchNorm3d])\n",
    "test_eq(layer_types(FlexConvLayer(1, 2, bn=True)), [torch.nn.modules.conv.Conv3d, torch.nn.modules.batchnorm.BatchNorm3d])\n",
    "test_eq(layer_types(FlexConvLayer(1, 2, bn=True, ups=True)), [torch.nn.modules.upsampling.Upsample, torch.nn.modules.conv.Conv3d, torch.nn.modules.batchnorm.BatchNorm3d])\n",
    "test_eq(layer_types(FlexConvLayer(1, 2, bn=True, ups=True, act_fn=nn.ELU)), [torch.nn.modules.upsampling.Upsample, torch.nn.modules.conv.Conv3d, torch.nn.modules.batchnorm.BatchNorm3d, torch.nn.modules.activation.ELU])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def init_default(m, func=nn.init.kaiming_normal_):\n",
    "    \"Initialize `m` weights with `func` and set `bias` to 0.\"\n",
    "    if func and hasattr(m, 'weight'): func(m.weight)\n",
    "    with torch.no_grad():\n",
    "        if getattr(m, 'bias', None) is not None: m.bias.fill_(0.)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "class FlexUnetEncoder(nn.Module):\n",
    "    '''Creates flexible encoder for Unets\n",
    "       \\n`ni`: in_channels\n",
    "       \\n`nf`: out_channels\n",
    "       \\n`ks`: kernal_size\n",
    "       \\n`st`: stride\n",
    "       \\n`pd`: padding default is 1 \n",
    "       \\n`bn`: adds BatchNorm layer if `True`\n",
    "       \\n`act_fn`: activation function\n",
    "       \\n`conv_depth`: number of conv layers\n",
    "       '''\n",
    "    \n",
    "    def __init__(self, ni, nf, ks, st, pd, conv_depth, ndim=3,  act_fn=nn.ELU, **kwargs):\n",
    "        super().__init__()\n",
    "        nf = nf\n",
    "        self.module_dict = nn.ModuleDict()\n",
    "        self.module_dict[f'pass_n'] = FlexConvLayer(ni, nf, act_fn=act_fn, ndim=ndim, **kwargs)\n",
    "        self.module_dict[f'save_n'] = FlexConvLayer(nf, nf, act_fn=act_fn, ndim=ndim, **kwargs)\n",
    "        for i in range(conv_depth):\n",
    "            self.module_dict[f'pass_{i}_k'] = nn.Sequential(FlexConvLayer(nf, nf, ks=ks-1, st=st + 1, act_fn=act_fn, pd=pd, ndim=ndim, **kwargs))\n",
    "            self.module_dict[f'save_{i}'] = nn.Sequential(FlexConvLayer(nf, nf*2, ks=ks, st=st, act_fn=act_fn, ndim=ndim, **kwargs), )\n",
    "            self.module_dict[f'pass_{i}'] = nn.Sequential(FlexConvLayer(nf*2, nf*2, ks=ks, st=st, act_fn=act_fn, ndim=ndim, **kwargs))\n",
    "            nf *=2\n",
    "    def forward(self, x):\n",
    "        features = []\n",
    "        for i in self.module_dict:\n",
    "            if     i.startswith('pass'): x = self.module_dict[i](x)\n",
    "            else:  x = self.module_dict[i](x) ;features.append(x)\n",
    "        return (x, features[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h2 id=\"FlexUnetEncoder\" class=\"doc_header\"><code>class</code> <code>FlexUnetEncoder</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h2>\n",
       "\n",
       "> <code>FlexUnetEncoder</code>(**`ni`**, **`nf`**, **`ks`**, **`st`**, **`pd`**, **`conv_depth`**, **`ndim`**=*`3`*, **`act_fn`**=*`'ELU'`*, **\\*\\*`kwargs`**) :: `Module`\n",
       "\n",
       "Creates flexible encoder for Unets\n",
       "       \n",
       "`ni`: in_channels\n",
       "       \n",
       "`nf`: out_channels\n",
       "       \n",
       "`ks`: kernal_size\n",
       "       \n",
       "`st`: stride\n",
       "       \n",
       "`pd`: padding default is 1 \n",
       "       \n",
       "`bn`: adds BatchNorm layer if `True`\n",
       "       \n",
       "`act_fn`: activation function\n",
       "       \n",
       "`conv_depth`: number of conv layers\n",
       "       "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(FlexUnetEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FlexUnetEncoder(\n",
       "  (module_dict): ModuleDict(\n",
       "    (pass_n): FlexConvLayer(\n",
       "      (0): Conv2d(1, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ELU(alpha=1.0)\n",
       "    )\n",
       "    (save_n): FlexConvLayer(\n",
       "      (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ELU(alpha=1.0)\n",
       "    )\n",
       "    (pass_0_k): Sequential(\n",
       "      (0): FlexConvLayer(\n",
       "        (0): Conv2d(48, 48, kernel_size=(2, 2), stride=(2, 2))\n",
       "        (1): ELU(alpha=1.0)\n",
       "      )\n",
       "    )\n",
       "    (save_0): Sequential(\n",
       "      (0): FlexConvLayer(\n",
       "        (0): Conv2d(48, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ELU(alpha=1.0)\n",
       "      )\n",
       "    )\n",
       "    (pass_0): Sequential(\n",
       "      (0): FlexConvLayer(\n",
       "        (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ELU(alpha=1.0)\n",
       "      )\n",
       "    )\n",
       "    (pass_1_k): Sequential(\n",
       "      (0): FlexConvLayer(\n",
       "        (0): Conv2d(96, 96, kernel_size=(2, 2), stride=(2, 2))\n",
       "        (1): ELU(alpha=1.0)\n",
       "      )\n",
       "    )\n",
       "    (save_1): Sequential(\n",
       "      (0): FlexConvLayer(\n",
       "        (0): Conv2d(96, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ELU(alpha=1.0)\n",
       "      )\n",
       "    )\n",
       "    (pass_1): Sequential(\n",
       "      (0): FlexConvLayer(\n",
       "        (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ELU(alpha=1.0)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2d\n",
    "tst_encoder = FlexUnetEncoder(1, 48, 3, 1, 0, conv_depth=2, ndim=2)\n",
    "tst_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FlexUnetEncoder(\n",
       "  (module_dict): ModuleDict(\n",
       "    (pass_n): FlexConvLayer(\n",
       "      (0): Conv3d(1, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (1): ELU(alpha=1.0)\n",
       "    )\n",
       "    (save_n): FlexConvLayer(\n",
       "      (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (1): ELU(alpha=1.0)\n",
       "    )\n",
       "    (pass_0_k): Sequential(\n",
       "      (0): FlexConvLayer(\n",
       "        (0): Conv3d(48, 48, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
       "        (1): ELU(alpha=1.0)\n",
       "      )\n",
       "    )\n",
       "    (save_0): Sequential(\n",
       "      (0): FlexConvLayer(\n",
       "        (0): Conv3d(48, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "        (1): ELU(alpha=1.0)\n",
       "      )\n",
       "    )\n",
       "    (pass_0): Sequential(\n",
       "      (0): FlexConvLayer(\n",
       "        (0): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "        (1): ELU(alpha=1.0)\n",
       "      )\n",
       "    )\n",
       "    (pass_1_k): Sequential(\n",
       "      (0): FlexConvLayer(\n",
       "        (0): Conv3d(96, 96, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
       "        (1): ELU(alpha=1.0)\n",
       "      )\n",
       "    )\n",
       "    (save_1): Sequential(\n",
       "      (0): FlexConvLayer(\n",
       "        (0): Conv3d(96, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "        (1): ELU(alpha=1.0)\n",
       "      )\n",
       "    )\n",
       "    (pass_1): Sequential(\n",
       "      (0): FlexConvLayer(\n",
       "        (0): Conv3d(192, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "        (1): ELU(alpha=1.0)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3d\n",
    "tst_encoder = FlexUnetEncoder(1, 48, 3, 1, 0, conv_depth=2, ndim=3)\n",
    "tst_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_batch = torch.rand(20, 1, 20, 20, 20)\n",
    "res = tst_encoder(x_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(len(res), 2)\n",
    "test_eq(res[0].shape[1], 192)\n",
    "test_eq(len(res[1]), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([20, 48, 20, 20, 20]), torch.Size([20, 96, 10, 10, 10]))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[1][0].shape, res[1][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(len(extract_layer(tst_encoder)), 8)\n",
    "test_eq(layer_types(extract_layer(tst_encoder))[:1], [torch.nn.modules.conv.Conv3d])\n",
    "test_eq(layer_types(extract_layer(tst_encoder)), [torch.nn.modules.conv.Conv3d]*8)\n",
    "test_eq(getattr(extract_layer(tst_encoder)[0], 'kernel_size'), (3, 3, 3))\n",
    "test_eq(getattr(extract_layer(tst_encoder)[0], 'stride'), (1, 1, 1))\n",
    "test_eq(getattr(extract_layer(tst_encoder)[0], 'padding'), (1, 1, 1))\n",
    "test_eq(getattr(extract_layer(tst_encoder)[2], 'padding'), (0, 0, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "class FlexUnetDecoder(nn.Module):\n",
    "    '''Creates flexible encoder for Unets\n",
    "       \\n`nf`: out_channels\n",
    "       \\n`ks`: kernal_size\n",
    "       \\n`st`: stride\n",
    "       \\n`pd`: padding default is 1 \n",
    "       \\n`conv_depth`: number of conv layers\n",
    "       ''' \n",
    "    def __init__(self, nf,  ks, st, pd, conv_depth, ndim=3,  act_fn=nn.ELU, **kwargs):\n",
    "        super().__init__()\n",
    "        nf = self._get_enc_filter(nf, conv_depth)\n",
    "        self.module_dict = nn.ModuleDict()\n",
    "\n",
    "        for i in range(conv_depth):\n",
    "            self.module_dict[f'conc_{i}'] = nn.Sequential(FlexConvLayer(nf, nf//2, ks=ks, st=st, ups = True, act_fn=act_fn, pd=pd, ndim=ndim, **kwargs))\n",
    "            self.module_dict[f'pass_{i}'] = nn.Sequential(FlexConvLayer(nf, nf//2, ks=ks, st=st, act_fn=act_fn, ndim=ndim, **kwargs),\n",
    "                                                          FlexConvLayer(nf//2, nf//2, ks=ks, st=st, act_fn=act_fn, ndim=ndim, **kwargs))\n",
    "            nf //=2\n",
    "            \n",
    "    def forward(self, x, features):\n",
    "        for i in self.module_dict:\n",
    "            if i.startswith('conc'): \n",
    "                  x = self.module_dict[i](x)\n",
    "                  x = torch.cat([x,features.pop()],1) \n",
    "            else: x = self.module_dict[i](x)\n",
    "        return x\n",
    "    \n",
    "    @staticmethod\n",
    "    def _get_enc_filter(nf, conv_depth):\n",
    "        nf = nf\n",
    "        for i in range(conv_depth): nf *=2 \n",
    "        return nf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h2 id=\"FlexUnetDecoder\" class=\"doc_header\"><code>class</code> <code>FlexUnetDecoder</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h2>\n",
       "\n",
       "> <code>FlexUnetDecoder</code>(**`nf`**, **`ks`**, **`st`**, **`pd`**, **`conv_depth`**, **`ndim`**=*`3`*, **`act_fn`**=*`'ELU'`*, **\\*\\*`kwargs`**) :: `Module`\n",
       "\n",
       "Creates flexible encoder for Unets\n",
       "       \n",
       "`nf`: out_channels\n",
       "       \n",
       "`ks`: kernal_size\n",
       "       \n",
       "`st`: stride\n",
       "       \n",
       "`pd`: padding default is 1 \n",
       "       \n",
       "`conv_depth`: number of conv layers\n",
       "       "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(FlexUnetDecoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "nf_enc_in = 48\n",
    "conv_depth = 2\n",
    "ndim = 3\n",
    "ks = 3\n",
    "st = 1\n",
    "pd = 1\n",
    "act_fn = nn.ELU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FlexUnetDecoder(\n",
       "  (module_dict): ModuleDict(\n",
       "    (conc_0): Sequential(\n",
       "      (0): FlexConvLayer(\n",
       "        (0): Upsample(scale_factor=2.0, mode=nearest)\n",
       "        (1): Conv3d(192, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "        (2): ELU(alpha=1.0)\n",
       "      )\n",
       "    )\n",
       "    (pass_0): Sequential(\n",
       "      (0): FlexConvLayer(\n",
       "        (0): Conv3d(192, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "        (1): ELU(alpha=1.0)\n",
       "      )\n",
       "      (1): FlexConvLayer(\n",
       "        (0): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "        (1): ELU(alpha=1.0)\n",
       "      )\n",
       "    )\n",
       "    (conc_1): Sequential(\n",
       "      (0): FlexConvLayer(\n",
       "        (0): Upsample(scale_factor=2.0, mode=nearest)\n",
       "        (1): Conv3d(96, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "        (2): ELU(alpha=1.0)\n",
       "      )\n",
       "    )\n",
       "    (pass_1): Sequential(\n",
       "      (0): FlexConvLayer(\n",
       "        (0): Conv3d(96, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "        (1): ELU(alpha=1.0)\n",
       "      )\n",
       "      (1): FlexConvLayer(\n",
       "        (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "        (1): ELU(alpha=1.0)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst_decoder = FlexUnetDecoder(nf_enc_in, ks, st, pd, conv_depth)\n",
    "tst_decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_encoder = FlexUnetEncoder(1, 48, 3, 1, 0, conv_depth=2, ndim=3)\n",
    "x_batch     = torch.rand(20, 1, 20, 20, 20)\n",
    "res         = tst_encoder(x_batch)\n",
    "res_dec     = tst_decoder(*res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(res_dec.shape[1], nf_enc_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SUNET(nn.Module):\n",
    "    '''General UNET for 2D or 3D\n",
    "       \\n`ni`: in_channels\n",
    "       \\n`nf`: out_channels\n",
    "       \\n`ks`: kernal_size\n",
    "       \\n`st`: stride\n",
    "       \\n`pd`: padding default is 1 \n",
    "       \\n`ndim`: (2, 3) 2D or 3D depending on dimensions\n",
    "       \\n`conv_depth`: number of conv layers\n",
    "    '''\n",
    "    def __init__(self, ni, nc, ks, st, pd, conv_depth, ndim, **kwargs):\n",
    "        super().__init__()\n",
    "        self.encoder = FlexUnetEncoder(ni, nc, ks, st, pd, conv_depth, ndim, **kwargs)\n",
    "        self.decoder = FlexUnetDecoder(nc, ks, st, pd+1, conv_depth, ndim, **kwargs)\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(*x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h2 id=\"SUNET\" class=\"doc_header\"><code>class</code> <code>SUNET</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h2>\n",
       "\n",
       "> <code>SUNET</code>(**`ni`**, **`nc`**, **`ks`**, **`st`**, **`pd`**, **`conv_depth`**, **`ndim`**, **\\*\\*`kwargs`**) :: `Module`\n",
       "\n",
       "General UNET for 2D or 3D\n",
       "       \n",
       "`ni`: in_channels\n",
       "       \n",
       "`nf`: out_channels\n",
       "       \n",
       "`ks`: kernal_size\n",
       "       \n",
       "`st`: stride\n",
       "       \n",
       "`pd`: padding default is 1 \n",
       "       \n",
       "`ndim`: (2, 3) 2D or 3D depending on dimensions\n",
       "       \n",
       "`conv_depth`: number of conv layers\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(SUNET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SUNET(\n",
       "  (encoder): FlexUnetEncoder(\n",
       "    (module_dict): ModuleDict(\n",
       "      (pass_n): FlexConvLayer(\n",
       "        (0): Conv3d(1, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "        (1): ELU(alpha=1.0)\n",
       "      )\n",
       "      (save_n): FlexConvLayer(\n",
       "        (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "        (1): ELU(alpha=1.0)\n",
       "      )\n",
       "      (pass_0_k): Sequential(\n",
       "        (0): FlexConvLayer(\n",
       "          (0): Conv3d(48, 48, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
       "          (1): ELU(alpha=1.0)\n",
       "        )\n",
       "      )\n",
       "      (save_0): Sequential(\n",
       "        (0): FlexConvLayer(\n",
       "          (0): Conv3d(48, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (1): ELU(alpha=1.0)\n",
       "        )\n",
       "      )\n",
       "      (pass_0): Sequential(\n",
       "        (0): FlexConvLayer(\n",
       "          (0): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (1): ELU(alpha=1.0)\n",
       "        )\n",
       "      )\n",
       "      (pass_1_k): Sequential(\n",
       "        (0): FlexConvLayer(\n",
       "          (0): Conv3d(96, 96, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
       "          (1): ELU(alpha=1.0)\n",
       "        )\n",
       "      )\n",
       "      (save_1): Sequential(\n",
       "        (0): FlexConvLayer(\n",
       "          (0): Conv3d(96, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (1): ELU(alpha=1.0)\n",
       "        )\n",
       "      )\n",
       "      (pass_1): Sequential(\n",
       "        (0): FlexConvLayer(\n",
       "          (0): Conv3d(192, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (1): ELU(alpha=1.0)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): FlexUnetDecoder(\n",
       "    (module_dict): ModuleDict(\n",
       "      (conc_0): Sequential(\n",
       "        (0): FlexConvLayer(\n",
       "          (0): Upsample(scale_factor=2.0, mode=nearest)\n",
       "          (1): Conv3d(192, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (2): ELU(alpha=1.0)\n",
       "        )\n",
       "      )\n",
       "      (pass_0): Sequential(\n",
       "        (0): FlexConvLayer(\n",
       "          (0): Conv3d(192, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (1): ELU(alpha=1.0)\n",
       "        )\n",
       "        (1): FlexConvLayer(\n",
       "          (0): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (1): ELU(alpha=1.0)\n",
       "        )\n",
       "      )\n",
       "      (conc_1): Sequential(\n",
       "        (0): FlexConvLayer(\n",
       "          (0): Upsample(scale_factor=2.0, mode=nearest)\n",
       "          (1): Conv3d(96, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (2): ELU(alpha=1.0)\n",
       "        )\n",
       "      )\n",
       "      (pass_1): Sequential(\n",
       "        (0): FlexConvLayer(\n",
       "          (0): Conv3d(96, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (1): ELU(alpha=1.0)\n",
       "        )\n",
       "        (1): FlexConvLayer(\n",
       "          (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (1): ELU(alpha=1.0)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3d\n",
    "tst_unet = SUNET(1, 48, 3, 1, 0, 2, 3)\n",
    "tst_unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_batch = torch.rand(20, 1, 20, 20, 20)\n",
    "res     = tst_unet(x_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(res.shape[1], 48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SUNET(\n",
       "  (encoder): FlexUnetEncoder(\n",
       "    (module_dict): ModuleDict(\n",
       "      (pass_n): FlexConvLayer(\n",
       "        (0): Conv2d(1, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ELU(alpha=1.0)\n",
       "      )\n",
       "      (save_n): FlexConvLayer(\n",
       "        (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ELU(alpha=1.0)\n",
       "      )\n",
       "      (pass_0_k): Sequential(\n",
       "        (0): FlexConvLayer(\n",
       "          (0): Conv2d(48, 48, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (1): ELU(alpha=1.0)\n",
       "        )\n",
       "      )\n",
       "      (save_0): Sequential(\n",
       "        (0): FlexConvLayer(\n",
       "          (0): Conv2d(48, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ELU(alpha=1.0)\n",
       "        )\n",
       "      )\n",
       "      (pass_0): Sequential(\n",
       "        (0): FlexConvLayer(\n",
       "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ELU(alpha=1.0)\n",
       "        )\n",
       "      )\n",
       "      (pass_1_k): Sequential(\n",
       "        (0): FlexConvLayer(\n",
       "          (0): Conv2d(96, 96, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (1): ELU(alpha=1.0)\n",
       "        )\n",
       "      )\n",
       "      (save_1): Sequential(\n",
       "        (0): FlexConvLayer(\n",
       "          (0): Conv2d(96, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ELU(alpha=1.0)\n",
       "        )\n",
       "      )\n",
       "      (pass_1): Sequential(\n",
       "        (0): FlexConvLayer(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ELU(alpha=1.0)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): FlexUnetDecoder(\n",
       "    (module_dict): ModuleDict(\n",
       "      (conc_0): Sequential(\n",
       "        (0): FlexConvLayer(\n",
       "          (0): Upsample(scale_factor=2.0, mode=nearest)\n",
       "          (1): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (2): ELU(alpha=1.0)\n",
       "        )\n",
       "      )\n",
       "      (pass_0): Sequential(\n",
       "        (0): FlexConvLayer(\n",
       "          (0): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ELU(alpha=1.0)\n",
       "        )\n",
       "        (1): FlexConvLayer(\n",
       "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ELU(alpha=1.0)\n",
       "        )\n",
       "      )\n",
       "      (conc_1): Sequential(\n",
       "        (0): FlexConvLayer(\n",
       "          (0): Upsample(scale_factor=2.0, mode=nearest)\n",
       "          (1): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (2): ELU(alpha=1.0)\n",
       "        )\n",
       "      )\n",
       "      (pass_1): Sequential(\n",
       "        (0): FlexConvLayer(\n",
       "          (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ELU(alpha=1.0)\n",
       "        )\n",
       "        (1): FlexConvLayer(\n",
       "          (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ELU(alpha=1.0)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2d unet\n",
    "tst_unet = SUNET(1, 48, 3, 1, 0, 2, 2)\n",
    "tst_unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_models.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
