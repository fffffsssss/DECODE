{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    "> Classes and helper fuction for creating flexible 2D and 3D unets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *\n",
    "from pdb import set_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _get_conv(ndim: int):\n",
    "    \"Get Convolution Layer of any dimension\"\n",
    "    assert 1 <= ndim <=3\n",
    "    return getattr(nn, f'Conv{ndim}d')\n",
    "\n",
    "def _get_bn(ndim: int):\n",
    "    \"Get BatchNorm Layer of any dimension\"\n",
    "    assert 1 <= ndim <=3\n",
    "    return getattr(nn, f'BatchNorm{ndim}d')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.nn.modules.batchnorm.BatchNorm2d"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_get_bn(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(_get_conv(1), torch.nn.modules.conv.Conv1d)\n",
    "test_eq(_get_conv(2), torch.nn.modules.conv.Conv2d)\n",
    "test_eq(_get_conv(3), torch.nn.modules.conv.Conv3d)\n",
    "test_eq(_get_bn(1), torch.nn.modules.batchnorm.BatchNorm1d)\n",
    "test_eq(_get_bn(2), torch.nn.modules.batchnorm.BatchNorm2d)\n",
    "test_eq(_get_bn(3), torch.nn.modules.batchnorm.BatchNorm3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"_get_conv\" class=\"doc_header\"><code>_get_conv</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>_get_conv</code>(**`ndim`**:`int`)\n",
       "\n",
       "Get Convolution Layer of any dimension"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(_get_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"_get_bn\" class=\"doc_header\"><code>_get_bn</code><a href=\"__main__.py#L7\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>_get_bn</code>(**`ndim`**:`int`)\n",
       "\n",
       "Get BatchNorm Layer of any dimension"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(_get_bn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def init_func(m, func=nn.init.kaiming_normal_):\n",
    "    \"Initialize pytorch model `m` weights with `func`\"\n",
    "    if func and hasattr(m, 'weight'): func(m.weight)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"init_func\" class=\"doc_header\"><code>init_func</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>init_func</code>(**`m`**, **`func`**=*`'kaiming_normal_'`*)\n",
       "\n",
       "Initialize pytorch model `m` weights with `func`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(init_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "def layer_types(m):\n",
    "    \"returns list of pytorch models type\"\n",
    "    if isinstance(m, list): return list(map(type, m))\n",
    "    return list(map(type, m.children()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def extract_layer(m, name=torch.nn.modules.Conv3d):\n",
    "    res = []\n",
    "    for child in m.children():\n",
    "        for layer in child.modules():\n",
    "            if(isinstance(layer,name)):\n",
    "                res.append(layer)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class FlexConvLayer(nn.Sequential):\n",
    "    '''\n",
    "      Create Flexible Convolution layer.\n",
    "    \n",
    "      This module allows to create 1, 2, or 3D convolutional layers containing (optional) activation function,\n",
    "      batch normalization, upsampling or additional Pytorch Classes \n",
    "      \n",
    "      Parameters:\n",
    "       \\n`ni`: in_channels\n",
    "       \\n`nf`: out_channels\n",
    "       \\n`ks`: kernal_size\n",
    "       \\n`st`: stride\n",
    "       \\n`pd`: padding default is 1 \n",
    "       \\n`ups`: adds Upsampling layer if `True`\n",
    "       \\n`sf`: scale factore if `ups` = True  upsampling layer\n",
    "       \\n`bn`: adds BatchNorm layer if `True`\n",
    "       \\n`ndim`: number of dimensions for layers e.g if 3 will create `nn.Conv3D` or `nn.BatchNorm3d`\n",
    "       \\n`func`: initiation function by default `nn.init.kaiming_normal_`\n",
    "       \\n`xtra`: adds any extra nn.Layers\n",
    "       \\n`act_fn`: activation function\n",
    "       \n",
    "       \\nReturns:\n",
    "       Sequential model containing specified Paramaters \n",
    "       \n",
    "       '''  \n",
    "    def __init__(self, ni: int, nf: int, ks: int=3, st:int=1, ndim: int=3, sf: int=2, pd: int=None, act_fn=None, bn: bool=False, ups: bool=False, xtra=None, func=nn.init.kaiming_normal_, **kwargs):\n",
    "        layers = []\n",
    "        if pd is None: pd = 1\n",
    "        conv_l = _get_conv(ndim)(in_channels=ni, out_channels=nf,kernel_size =ks, stride=st, padding=pd, **kwargs)\n",
    "        init_func(conv_l, func)\n",
    "        layers.append(conv_l)\n",
    "        if ups       : layers.insert(0, nn.Upsample(scale_factor=sf))\n",
    "        if bn        : layers.append(_get_bn(ndim)(nf))\n",
    "        if act_fn    : layers.append(act_fn())\n",
    "        if xtra      : layers.append(xtra)\n",
    "        super().__init__(*layers)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h2 id=\"FlexConvLayer\" class=\"doc_header\"><code>class</code> <code>FlexConvLayer</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h2>\n",
       "\n",
       "> <code>FlexConvLayer</code>(**`ni`**:`int`, **`nf`**:`int`, **`ks`**:`int`=*`3`*, **`st`**:`int`=*`1`*, **`ndim`**:`int`=*`3`*, **`sf`**:`int`=*`2`*, **`pd`**:`int`=*`None`*, **`act_fn`**=*`None`*, **`bn`**:`bool`=*`False`*, **`ups`**:`bool`=*`False`*, **`xtra`**=*`None`*, **`func`**=*`'kaiming_normal_'`*, **\\*\\*`kwargs`**) :: `Sequential`\n",
       "\n",
       "      Create Flexible Convolution layer.\n",
       "    \n",
       "      This module allows to create 1, 2, or 3D convolutional layers containing (optional) activation function,\n",
       "      batch normalization, upsampling or additional Pytorch Classes \n",
       "      \n",
       "      Parameters:\n",
       "       \n",
       "`ni`: in_channels\n",
       "       \n",
       "`nf`: out_channels\n",
       "       \n",
       "`ks`: kernal_size\n",
       "       \n",
       "`st`: stride\n",
       "       \n",
       "`pd`: padding default is 1 \n",
       "       \n",
       "`ups`: adds Upsampling layer if `True`\n",
       "       \n",
       "`sf`: scale factore if `ups` = True  upsampling layer\n",
       "       \n",
       "`bn`: adds BatchNorm layer if `True`\n",
       "       \n",
       "`ndim`: number of dimensions for layers e.g if 3 will create `nn.Conv3D` or `nn.BatchNorm3d`\n",
       "       \n",
       "`func`: initiation function by default `nn.init.kaiming_normal_`\n",
       "       \n",
       "`xtra`: adds any extra nn.Layers\n",
       "       \n",
       "`act_fn`: activation function\n",
       "       \n",
       "       \n",
       "Returns:\n",
       "       Sequential model containing specified Paramaters \n",
       "       \n",
       "       "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(FlexConvLayer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FlexConvLayer(\n",
       "  (0): Conv2d(1, 2, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
       "  (1): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " #2D convolutional layer with in_channel=1, out_channel=2 and BatchNorm\n",
    "FlexConvLayer(1, 2, ks=4, bn=True, ndim=2)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.children at 0x7f14b94eab50>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3D convolutional layer with in_channel=1, out_channel=2 and ReLU activation function \n",
    "FlexConvLayer(1, 2, ndim=3, act_fn = nn.ReLU).children()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(layer_types(FlexConvLayer(1, 2)), [torch.nn.modules.conv.Conv3d])\n",
    "test_eq(layer_types(FlexConvLayer(1, 2, bn=True)), [torch.nn.modules.conv.Conv3d, torch.nn.modules.batchnorm.BatchNorm3d])\n",
    "test_eq(layer_types(FlexConvLayer(1, 2, bn=True, ndim=2)), [torch.nn.modules.conv.Conv2d, torch.nn.modules.batchnorm.BatchNorm2d])\n",
    "test_eq(layer_types(FlexConvLayer(1, 2, bn=True, ups=True)), [torch.nn.modules.upsampling.Upsample, torch.nn.modules.conv.Conv3d, torch.nn.modules.batchnorm.BatchNorm3d])\n",
    "test_eq(layer_types(FlexConvLayer(1, 2, bn=True, ups=True, act_fn=nn.ELU)), [torch.nn.modules.upsampling.Upsample, torch.nn.modules.conv.Conv3d, torch.nn.modules.batchnorm.BatchNorm3d, torch.nn.modules.activation.ELU])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def init_default(m, func=nn.init.kaiming_normal_):\n",
    "    \"Initialize `m` weights with `func` and set `bias` to 0.\"\n",
    "    if func and hasattr(m, 'weight'): func(m.weight)\n",
    "    with torch.no_grad():\n",
    "        if getattr(m, 'bias', None) is not None: m.bias.fill_(0.)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "class FlexUnetEncoder(nn.Module):\n",
    "    '''\n",
    "    Creates flexible encoder for Unets.\n",
    "        \n",
    "    Provided convolution depth will generate unet encoder based on `FlexConvLayer`. During forward pass will also return `features` tensor, contaning stored features which will be used in decoder for  concatinating during  upsampling. Last element of `feature` is `x` which used to enter first layer in `decoder`\n",
    "       \n",
    "    Parameters:\n",
    "    \\n`ni`: in_channels\n",
    "    \\n`nf`: out_channels\n",
    "    \\n`ks`: kernal_size\n",
    "    \\n`st`: stride\n",
    "    \\n`pd`: padding default is 1 \n",
    "    \\n`bn`: adds BatchNorm layer if `True`\n",
    "    \\n`act_fn`: activation function\n",
    "    \\n`conv_depth`: number of conv layers\n",
    "    \n",
    "    \\nReturns:\n",
    "    Sequential encoder, and feautre list \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    def __init__(self, ni: int, nf: int, ks: int, st: int, pd: int, conv_depth: int, ndim: int=3,  act_fn=nn.ELU, **kwargs):\n",
    "        super().__init__()\n",
    "        nf = nf\n",
    "        self.module_dict = nn.ModuleDict()\n",
    "        self.module_dict['pass_n'] = FlexConvLayer(ni, nf, act_fn=act_fn, ndim=ndim, **kwargs)\n",
    "        self.module_dict['save_n'] = FlexConvLayer(nf, nf, act_fn=act_fn, ndim=ndim, **kwargs)\n",
    "        for i in range(conv_depth):\n",
    "            self.module_dict[f'pass_{i}_k'] = nn.Sequential(FlexConvLayer(nf, nf, ks=ks-1, st=st + 1, act_fn=act_fn, pd=pd, ndim=ndim, **kwargs))\n",
    "            self.module_dict[f'save_{i}']  = nn.Sequential(FlexConvLayer(nf, nf*2, ks=ks, st=st, act_fn=act_fn, ndim=ndim, **kwargs), )\n",
    "            self.module_dict[f'pass_{i}'] = nn.Sequential(FlexConvLayer(nf*2, nf*2, ks=ks, st=st, act_fn=act_fn, ndim=ndim, **kwargs))\n",
    "            nf *=2\n",
    "    def forward(self, x):\n",
    "        features = []\n",
    "        for i in self.module_dict:\n",
    "            x = self.module_dict[i](x)\n",
    "            if  i.startswith('save'): features.append(x)\n",
    "                \n",
    "        features = features[:-1]; \n",
    "        features.append(x)\n",
    "        return features\n",
    "    \n",
    "    \n",
    "#RENAME everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h2 id=\"FlexUnetEncoder\" class=\"doc_header\"><code>class</code> <code>FlexUnetEncoder</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h2>\n",
       "\n",
       "> <code>FlexUnetEncoder</code>(**`ni`**:`int`, **`nf`**:`int`, **`ks`**:`int`, **`st`**:`int`, **`pd`**:`int`, **`conv_depth`**:`int`, **`ndim`**:`int`=*`3`*, **`act_fn`**=*`'ELU'`*, **\\*\\*`kwargs`**) :: `Module`\n",
       "\n",
       "    Creates flexible encoder for Unets.\n",
       "        \n",
       "    Provided convolution depth will generate unet encoder based on [`FlexConvLayer`](/nbdev_template/models#FlexConvLayer). During forward pass will also return `features` tensor, contaning stored features which will be used in decoder for  concatinating during  upsampling. Last element of `feature` is `x` which used to enter first layer in `decoder`\n",
       "       \n",
       "    Parameters:\n",
       "    \n",
       "`ni`: in_channels\n",
       "    \n",
       "`nf`: out_channels\n",
       "    \n",
       "`ks`: kernal_size\n",
       "    \n",
       "`st`: stride\n",
       "    \n",
       "`pd`: padding default is 1 \n",
       "    \n",
       "`bn`: adds BatchNorm layer if `True`\n",
       "    \n",
       "`act_fn`: activation function\n",
       "    \n",
       "`conv_depth`: number of conv layers\n",
       "    \n",
       "    \n",
       "Returns:\n",
       "    Sequential encoder, and feautre list \n",
       "    \n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(FlexUnetEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndim       = 2\n",
    "conv_depth = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FlexUnetEncoder(\n",
       "  (module_dict): ModuleDict(\n",
       "    (pass_n): FlexConvLayer(\n",
       "      (0): Conv3d(1, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (1): BatchNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ELU(alpha=1.0)\n",
       "    )\n",
       "    (save_n): FlexConvLayer(\n",
       "      (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (1): BatchNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ELU(alpha=1.0)\n",
       "    )\n",
       "    (pass_0_k): Sequential(\n",
       "      (0): FlexConvLayer(\n",
       "        (0): Conv3d(48, 48, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
       "        (1): BatchNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ELU(alpha=1.0)\n",
       "      )\n",
       "    )\n",
       "    (save_0): Sequential(\n",
       "      (0): FlexConvLayer(\n",
       "        (0): Conv3d(48, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "        (1): BatchNorm3d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ELU(alpha=1.0)\n",
       "      )\n",
       "    )\n",
       "    (pass_0): Sequential(\n",
       "      (0): FlexConvLayer(\n",
       "        (0): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "        (1): BatchNorm3d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ELU(alpha=1.0)\n",
       "      )\n",
       "    )\n",
       "    (pass_1_k): Sequential(\n",
       "      (0): FlexConvLayer(\n",
       "        (0): Conv3d(96, 96, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
       "        (1): BatchNorm3d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ELU(alpha=1.0)\n",
       "      )\n",
       "    )\n",
       "    (save_1): Sequential(\n",
       "      (0): FlexConvLayer(\n",
       "        (0): Conv3d(96, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "        (1): BatchNorm3d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ELU(alpha=1.0)\n",
       "      )\n",
       "    )\n",
       "    (pass_1): Sequential(\n",
       "      (0): FlexConvLayer(\n",
       "        (0): Conv3d(192, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "        (1): BatchNorm3d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ELU(alpha=1.0)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2d\n",
    "tst_encoder = FlexUnetEncoder(ni=1, nf =48, ks =3, st =1, pd =0, conv_depth=conv_depth, ndim=ndim)\n",
    "tst_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FlexUnetEncoder(\n",
       "  (module_dict): ModuleDict(\n",
       "    (pass_n): FlexConvLayer(\n",
       "      (0): Conv3d(1, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (1): ELU(alpha=1.0)\n",
       "    )\n",
       "    (save_n): FlexConvLayer(\n",
       "      (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (1): ELU(alpha=1.0)\n",
       "    )\n",
       "    (pass_0_k): Sequential(\n",
       "      (0): FlexConvLayer(\n",
       "        (0): Conv3d(48, 48, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
       "        (1): ELU(alpha=1.0)\n",
       "      )\n",
       "    )\n",
       "    (save_0): Sequential(\n",
       "      (0): FlexConvLayer(\n",
       "        (0): Conv3d(48, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "        (1): ELU(alpha=1.0)\n",
       "      )\n",
       "    )\n",
       "    (pass_0): Sequential(\n",
       "      (0): FlexConvLayer(\n",
       "        (0): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "        (1): ELU(alpha=1.0)\n",
       "      )\n",
       "    )\n",
       "    (pass_1_k): Sequential(\n",
       "      (0): FlexConvLayer(\n",
       "        (0): Conv3d(96, 96, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
       "        (1): ELU(alpha=1.0)\n",
       "      )\n",
       "    )\n",
       "    (save_1): Sequential(\n",
       "      (0): FlexConvLayer(\n",
       "        (0): Conv3d(96, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "        (1): ELU(alpha=1.0)\n",
       "      )\n",
       "    )\n",
       "    (pass_1): Sequential(\n",
       "      (0): FlexConvLayer(\n",
       "        (0): Conv3d(192, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "        (1): ELU(alpha=1.0)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3d\n",
    "ndim = 3\n",
    "tst_encoder = FlexUnetEncoder(1, 48, 3, 1, 0, conv_depth=conv_depth, ndim=ndim)\n",
    "tst_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_batch = torch.rand(20, 1, 20, 20, 20)\n",
    "res = tst_encoder(x_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(len(res), conv_depth + 1)\n",
    "test_eq(res[-1].shape[1], 192)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(len(extract_layer(tst_encoder)), 8)\n",
    "test_eq(layer_types(extract_layer(tst_encoder))[:1], [torch.nn.modules.conv.Conv3d])\n",
    "test_eq(layer_types(extract_layer(tst_encoder)), [torch.nn.modules.conv.Conv3d]*8)\n",
    "test_eq(getattr(extract_layer(tst_encoder)[0], 'kernel_size'), (3, 3, 3))\n",
    "test_eq(getattr(extract_layer(tst_encoder)[0], 'stride'), (1, 1, 1))\n",
    "test_eq(getattr(extract_layer(tst_encoder)[0], 'padding'), (1, 1, 1))\n",
    "test_eq(getattr(extract_layer(tst_encoder)[2], 'padding'), (0, 0, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "class FlexUnetDecoder(nn.Module):\n",
    "    '''\n",
    "    Creates flexible decoder for Unets.\n",
    "    \n",
    "    This class will autmatically create decoder based on encoder paramaters. In forward pass, it will take features generated from FlexUnetEcnder and concatinate them on upsampled layers. \n",
    "    \n",
    "    Parameters:\n",
    "    \\n`nf`: out_channels for the first layer in encoder\n",
    "    \\n`ks`: kernal_size\n",
    "    \\n`st`: stride\n",
    "    \\n`pd`: padding default is 1 \n",
    "    \\n`conv_depth`: number of conv layers\n",
    "    \\n`act_fn`: activation function by default its `nn.ELU`\n",
    "    \n",
    "    Returns:\n",
    "    Decoder Model, and output of unet Model wchich should match input Dimensions\n",
    "    ''' \n",
    "    def __init__(self, nf: int,  ks: int, st: int, pd: int, conv_depth: int, ndim=3,  act_fn=nn.ELU, **kwargs):\n",
    "        super().__init__()\n",
    "        nf = self._get_enc_filter(nf, conv_depth)\n",
    "        self.module_dict = nn.ModuleDict()\n",
    "\n",
    "        for i in range(conv_depth):\n",
    "            self.module_dict[f'conc_{i}'] = nn.Sequential(FlexConvLayer(nf, nf//2, ks=ks, st=st, ups = True, act_fn=act_fn, pd=pd, ndim=ndim, **kwargs))\n",
    "            self.module_dict[f'pass_{i}'] = nn.Sequential(FlexConvLayer(nf, nf//2, ks=ks, st=st, act_fn=act_fn, ndim=ndim, **kwargs),\n",
    "                                                          FlexConvLayer(nf//2, nf//2, ks=ks, st=st, act_fn=act_fn, ndim=ndim, **kwargs))\n",
    "            nf //=2\n",
    "            \n",
    "    def forward(self, features):\n",
    "        #x replaced with features \n",
    "        #rework this a bit \n",
    "        x = features.pop()\n",
    "        for i in self.module_dict:\n",
    "            if i.startswith('conc'): \n",
    "                  x = self.module_dict[i](x)\n",
    "                  x = torch.cat([x,features.pop()],1) \n",
    "            else: x = self.module_dict[i](x)\n",
    "        return x\n",
    "    \n",
    "    @staticmethod\n",
    "    def _get_enc_filter(nf, conv_depth):\n",
    "        '''calculates number of in filters for decoder model given conv_depth and nf\n",
    "        in the first conv layer in unet encoder'''\n",
    "        nf = nf\n",
    "        for i in range(conv_depth): nf *=2 \n",
    "        return nf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h2 id=\"FlexUnetDecoder\" class=\"doc_header\"><code>class</code> <code>FlexUnetDecoder</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h2>\n",
       "\n",
       "> <code>FlexUnetDecoder</code>(**`nf`**:`int`, **`ks`**:`int`, **`st`**:`int`, **`pd`**:`int`, **`conv_depth`**:`int`, **`ndim`**=*`3`*, **`act_fn`**=*`'ELU'`*, **\\*\\*`kwargs`**) :: `Module`\n",
       "\n",
       "    Creates flexible decoder for Unets.\n",
       "    \n",
       "    This class will autmatically create decoder based on encoder paramaters. In forward pass, it will take features generated from FlexUnetEcnder and concatinate them on upsampled layers. \n",
       "    \n",
       "    Parameters:\n",
       "    \n",
       "`nf`: out_channels for the first layer in encoder\n",
       "    \n",
       "`ks`: kernal_size\n",
       "    \n",
       "`st`: stride\n",
       "    \n",
       "`pd`: padding default is 1 \n",
       "    \n",
       "`conv_depth`: number of conv layers\n",
       "    \n",
       "`act_fn`: activation function by default its `nn.ELU`\n",
       "    \n",
       "    Returns:\n",
       "    Decoder Model, and output of unet Model wchich should match input Dimensions\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(FlexUnetDecoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "nf_enc_in = 48\n",
    "conv_depth = 2\n",
    "ndim = 3\n",
    "ks = 3\n",
    "st = 1\n",
    "pd = 1\n",
    "act_fn = nn.ELU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FlexUnetDecoder(\n",
       "  (module_dict): ModuleDict(\n",
       "    (conc_0): Sequential(\n",
       "      (0): FlexConvLayer(\n",
       "        (0): Upsample(scale_factor=2.0, mode=nearest)\n",
       "        (1): Conv3d(192, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "        (2): ELU(alpha=1.0)\n",
       "      )\n",
       "    )\n",
       "    (pass_0): Sequential(\n",
       "      (0): FlexConvLayer(\n",
       "        (0): Conv3d(192, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "        (1): ELU(alpha=1.0)\n",
       "      )\n",
       "      (1): FlexConvLayer(\n",
       "        (0): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "        (1): ELU(alpha=1.0)\n",
       "      )\n",
       "    )\n",
       "    (conc_1): Sequential(\n",
       "      (0): FlexConvLayer(\n",
       "        (0): Upsample(scale_factor=2.0, mode=nearest)\n",
       "        (1): Conv3d(96, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "        (2): ELU(alpha=1.0)\n",
       "      )\n",
       "    )\n",
       "    (pass_1): Sequential(\n",
       "      (0): FlexConvLayer(\n",
       "        (0): Conv3d(96, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "        (1): ELU(alpha=1.0)\n",
       "      )\n",
       "      (1): FlexConvLayer(\n",
       "        (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "        (1): ELU(alpha=1.0)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst_decoder = FlexUnetDecoder(nf_enc_in, ks, st, pd, conv_depth)\n",
    "tst_decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_encoder = FlexUnetEncoder(1, 48, 3, 1, 0, conv_depth=2, ndim=3)\n",
    "x_batch     = torch.rand(20, 1, 20, 20, 20)\n",
    "res         = tst_encoder(x_batch)\n",
    "res_dec     = tst_decoder(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(res_dec.shape[1], nf_enc_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SUNET(nn.Module):\n",
    "    '''\n",
    "    Generates 1D, 2D or 3D Unet.\n",
    "    \n",
    "    Autmatically genrates UNET model based on user specified paramaters\n",
    "    \n",
    "    Parameters:\n",
    "    \\n`ni`: in_channels\n",
    "    \\n`nf`: out_channels\n",
    "    \\n`ks`: kernal_size\n",
    "    \\n`st`: stride\n",
    "    \\n`pd`: padding default is 1 \n",
    "    \\n`ndim`: (1, 2, 3) 2D or 3D depending on dimensions\n",
    "    \\n`conv_depth`: number of conv layers\n",
    "    \\n **kwargs: see `FlexConvLayer` for generating flexible conv layers\n",
    "    \n",
    "    Returns:\n",
    "    \\n Unet Model\n",
    "    '''\n",
    "    def __init__(self, ni, nc, ks, st, pd, conv_depth, ndim, **kwargs):\n",
    "        super().__init__()\n",
    "        self.encoder = FlexUnetEncoder(ni, nc, ks, st, pd, conv_depth, ndim, **kwargs)\n",
    "        self.decoder = FlexUnetDecoder(nc, ks, st, pd+1, conv_depth, ndim, **kwargs)\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h2 id=\"SUNET\" class=\"doc_header\"><code>class</code> <code>SUNET</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h2>\n",
       "\n",
       "> <code>SUNET</code>(**`ni`**, **`nc`**, **`ks`**, **`st`**, **`pd`**, **`conv_depth`**, **`ndim`**, **\\*\\*`kwargs`**) :: `Module`\n",
       "\n",
       "    Generates 1D, 2D or 3D Unet.\n",
       "    \n",
       "    Autmatically genrates UNET model based on user specified paramaters\n",
       "    \n",
       "    Parameters:\n",
       "    \n",
       "`ni`: in_channels\n",
       "    \n",
       "`nf`: out_channels\n",
       "    \n",
       "`ks`: kernal_size\n",
       "    \n",
       "`st`: stride\n",
       "    \n",
       "`pd`: padding default is 1 \n",
       "    \n",
       "`ndim`: (1, 2, 3) 2D or 3D depending on dimensions\n",
       "    \n",
       "`conv_depth`: number of conv layers\n",
       "    \n",
       " **kwargs: see [`FlexConvLayer`](/nbdev_template/models#FlexConvLayer) for generating flexible conv layers\n",
       "    \n",
       "    Returns:\n",
       "    \n",
       " Unet Model\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(SUNET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SUNET(\n",
       "  (encoder): FlexUnetEncoder(\n",
       "    (module_dict): ModuleDict(\n",
       "      (pass_n): FlexConvLayer(\n",
       "        (0): Conv3d(1, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "        (1): ELU(alpha=1.0)\n",
       "      )\n",
       "      (save_n): FlexConvLayer(\n",
       "        (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "        (1): ELU(alpha=1.0)\n",
       "      )\n",
       "      (pass_0_k): Sequential(\n",
       "        (0): FlexConvLayer(\n",
       "          (0): Conv3d(48, 48, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
       "          (1): ELU(alpha=1.0)\n",
       "        )\n",
       "      )\n",
       "      (save_0): Sequential(\n",
       "        (0): FlexConvLayer(\n",
       "          (0): Conv3d(48, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (1): ELU(alpha=1.0)\n",
       "        )\n",
       "      )\n",
       "      (pass_0): Sequential(\n",
       "        (0): FlexConvLayer(\n",
       "          (0): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (1): ELU(alpha=1.0)\n",
       "        )\n",
       "      )\n",
       "      (pass_1_k): Sequential(\n",
       "        (0): FlexConvLayer(\n",
       "          (0): Conv3d(96, 96, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
       "          (1): ELU(alpha=1.0)\n",
       "        )\n",
       "      )\n",
       "      (save_1): Sequential(\n",
       "        (0): FlexConvLayer(\n",
       "          (0): Conv3d(96, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (1): ELU(alpha=1.0)\n",
       "        )\n",
       "      )\n",
       "      (pass_1): Sequential(\n",
       "        (0): FlexConvLayer(\n",
       "          (0): Conv3d(192, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (1): ELU(alpha=1.0)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): FlexUnetDecoder(\n",
       "    (module_dict): ModuleDict(\n",
       "      (conc_0): Sequential(\n",
       "        (0): FlexConvLayer(\n",
       "          (0): Upsample(scale_factor=2.0, mode=nearest)\n",
       "          (1): Conv3d(192, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (2): ELU(alpha=1.0)\n",
       "        )\n",
       "      )\n",
       "      (pass_0): Sequential(\n",
       "        (0): FlexConvLayer(\n",
       "          (0): Conv3d(192, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (1): ELU(alpha=1.0)\n",
       "        )\n",
       "        (1): FlexConvLayer(\n",
       "          (0): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (1): ELU(alpha=1.0)\n",
       "        )\n",
       "      )\n",
       "      (conc_1): Sequential(\n",
       "        (0): FlexConvLayer(\n",
       "          (0): Upsample(scale_factor=2.0, mode=nearest)\n",
       "          (1): Conv3d(96, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (2): ELU(alpha=1.0)\n",
       "        )\n",
       "      )\n",
       "      (pass_1): Sequential(\n",
       "        (0): FlexConvLayer(\n",
       "          (0): Conv3d(96, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (1): ELU(alpha=1.0)\n",
       "        )\n",
       "        (1): FlexConvLayer(\n",
       "          (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (1): ELU(alpha=1.0)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3d\n",
    "tst_unet = SUNET(1, 48, 3, 1, 0, 2, 3)\n",
    "tst_unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_batch = torch.rand(20, 1, 20, 20, 20)\n",
    "res     = tst_unet(x_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(res.shape[1], 48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SUNET(\n",
       "  (encoder): FlexUnetEncoder(\n",
       "    (module_dict): ModuleDict(\n",
       "      (pass_n): FlexConvLayer(\n",
       "        (0): Conv3d(1, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "        (1): ELU(alpha=1.0)\n",
       "      )\n",
       "      (save_n): FlexConvLayer(\n",
       "        (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "        (1): ELU(alpha=1.0)\n",
       "      )\n",
       "      (pass_0_k): Sequential(\n",
       "        (0): FlexConvLayer(\n",
       "          (0): Conv3d(48, 48, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
       "          (1): ELU(alpha=1.0)\n",
       "        )\n",
       "      )\n",
       "      (save_0): Sequential(\n",
       "        (0): FlexConvLayer(\n",
       "          (0): Conv3d(48, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (1): ELU(alpha=1.0)\n",
       "        )\n",
       "      )\n",
       "      (pass_0): Sequential(\n",
       "        (0): FlexConvLayer(\n",
       "          (0): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (1): ELU(alpha=1.0)\n",
       "        )\n",
       "      )\n",
       "      (pass_1_k): Sequential(\n",
       "        (0): FlexConvLayer(\n",
       "          (0): Conv3d(96, 96, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
       "          (1): ELU(alpha=1.0)\n",
       "        )\n",
       "      )\n",
       "      (save_1): Sequential(\n",
       "        (0): FlexConvLayer(\n",
       "          (0): Conv3d(96, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (1): ELU(alpha=1.0)\n",
       "        )\n",
       "      )\n",
       "      (pass_1): Sequential(\n",
       "        (0): FlexConvLayer(\n",
       "          (0): Conv3d(192, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (1): ELU(alpha=1.0)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): FlexUnetDecoder(\n",
       "    (module_dict): ModuleDict(\n",
       "      (conc_0): Sequential(\n",
       "        (0): FlexConvLayer(\n",
       "          (0): Upsample(scale_factor=2.0, mode=nearest)\n",
       "          (1): Conv3d(192, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (2): ELU(alpha=1.0)\n",
       "        )\n",
       "      )\n",
       "      (pass_0): Sequential(\n",
       "        (0): FlexConvLayer(\n",
       "          (0): Conv3d(192, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (1): ELU(alpha=1.0)\n",
       "        )\n",
       "        (1): FlexConvLayer(\n",
       "          (0): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (1): ELU(alpha=1.0)\n",
       "        )\n",
       "      )\n",
       "      (conc_1): Sequential(\n",
       "        (0): FlexConvLayer(\n",
       "          (0): Upsample(scale_factor=2.0, mode=nearest)\n",
       "          (1): Conv3d(96, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (2): ELU(alpha=1.0)\n",
       "        )\n",
       "      )\n",
       "      (pass_1): Sequential(\n",
       "        (0): FlexConvLayer(\n",
       "          (0): Conv3d(96, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (1): ELU(alpha=1.0)\n",
       "        )\n",
       "        (1): FlexConvLayer(\n",
       "          (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (1): ELU(alpha=1.0)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2d unet\n",
    "tst_unet = SUNET(1, 48, 3, 1, 0, 2, 3)\n",
    "tst_unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SUNET(\n",
       "  (encoder): FlexUnetEncoder(\n",
       "    (module_dict): ModuleDict(\n",
       "      (pass_n): FlexConvLayer(\n",
       "        (0): Conv3d(1, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "        (1): BatchNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (save_n): FlexConvLayer(\n",
       "        (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "        (1): BatchNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (pass_0_k): Sequential(\n",
       "        (0): FlexConvLayer(\n",
       "          (0): Conv3d(48, 48, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
       "          (1): BatchNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (save_0): Sequential(\n",
       "        (0): FlexConvLayer(\n",
       "          (0): Conv3d(48, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (1): BatchNorm3d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (pass_0): Sequential(\n",
       "        (0): FlexConvLayer(\n",
       "          (0): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (1): BatchNorm3d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (pass_1_k): Sequential(\n",
       "        (0): FlexConvLayer(\n",
       "          (0): Conv3d(96, 96, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
       "          (1): BatchNorm3d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (save_1): Sequential(\n",
       "        (0): FlexConvLayer(\n",
       "          (0): Conv3d(96, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (1): BatchNorm3d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (pass_1): Sequential(\n",
       "        (0): FlexConvLayer(\n",
       "          (0): Conv3d(192, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (1): BatchNorm3d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (pass_2_k): Sequential(\n",
       "        (0): FlexConvLayer(\n",
       "          (0): Conv3d(192, 192, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
       "          (1): BatchNorm3d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (save_2): Sequential(\n",
       "        (0): FlexConvLayer(\n",
       "          (0): Conv3d(192, 384, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (1): BatchNorm3d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (pass_2): Sequential(\n",
       "        (0): FlexConvLayer(\n",
       "          (0): Conv3d(384, 384, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (1): BatchNorm3d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (pass_3_k): Sequential(\n",
       "        (0): FlexConvLayer(\n",
       "          (0): Conv3d(384, 384, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
       "          (1): BatchNorm3d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (save_3): Sequential(\n",
       "        (0): FlexConvLayer(\n",
       "          (0): Conv3d(384, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (1): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (pass_3): Sequential(\n",
       "        (0): FlexConvLayer(\n",
       "          (0): Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (1): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (pass_4_k): Sequential(\n",
       "        (0): FlexConvLayer(\n",
       "          (0): Conv3d(768, 768, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
       "          (1): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (save_4): Sequential(\n",
       "        (0): FlexConvLayer(\n",
       "          (0): Conv3d(768, 1536, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (1): BatchNorm3d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (pass_4): Sequential(\n",
       "        (0): FlexConvLayer(\n",
       "          (0): Conv3d(1536, 1536, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (1): BatchNorm3d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): FlexUnetDecoder(\n",
       "    (module_dict): ModuleDict(\n",
       "      (conc_0): Sequential(\n",
       "        (0): FlexConvLayer(\n",
       "          (0): Upsample(scale_factor=2.0, mode=nearest)\n",
       "          (1): Conv3d(1536, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (2): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (pass_0): Sequential(\n",
       "        (0): FlexConvLayer(\n",
       "          (0): Conv3d(1536, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (1): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (1): FlexConvLayer(\n",
       "          (0): Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (1): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conc_1): Sequential(\n",
       "        (0): FlexConvLayer(\n",
       "          (0): Upsample(scale_factor=2.0, mode=nearest)\n",
       "          (1): Conv3d(768, 384, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (2): BatchNorm3d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (pass_1): Sequential(\n",
       "        (0): FlexConvLayer(\n",
       "          (0): Conv3d(768, 384, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (1): BatchNorm3d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (1): FlexConvLayer(\n",
       "          (0): Conv3d(384, 384, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (1): BatchNorm3d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conc_2): Sequential(\n",
       "        (0): FlexConvLayer(\n",
       "          (0): Upsample(scale_factor=2.0, mode=nearest)\n",
       "          (1): Conv3d(384, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (2): BatchNorm3d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (pass_2): Sequential(\n",
       "        (0): FlexConvLayer(\n",
       "          (0): Conv3d(384, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (1): BatchNorm3d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (1): FlexConvLayer(\n",
       "          (0): Conv3d(192, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (1): BatchNorm3d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conc_3): Sequential(\n",
       "        (0): FlexConvLayer(\n",
       "          (0): Upsample(scale_factor=2.0, mode=nearest)\n",
       "          (1): Conv3d(192, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (2): BatchNorm3d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (pass_3): Sequential(\n",
       "        (0): FlexConvLayer(\n",
       "          (0): Conv3d(192, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (1): BatchNorm3d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (1): FlexConvLayer(\n",
       "          (0): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (1): BatchNorm3d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conc_4): Sequential(\n",
       "        (0): FlexConvLayer(\n",
       "          (0): Upsample(scale_factor=2.0, mode=nearest)\n",
       "          (1): Conv3d(96, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (2): BatchNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (pass_4): Sequential(\n",
       "        (0): FlexConvLayer(\n",
       "          (0): Conv3d(96, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (1): BatchNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (1): FlexConvLayer(\n",
       "          (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (1): BatchNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst_unet = SUNET(1, 48, 3, 1, 0, 5, 3, bn=True, act_fn=nn.ReLU)\n",
    "tst_unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_models.ipynb.\n",
      "Converted 01_simulation.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
